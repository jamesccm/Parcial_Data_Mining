# -*- coding: utf-8 -*-
"""PARCIAL DE DATA MINING.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mYcHKqoIHZvi2JZ8OauSh_Bbey7jb6Oe
"""

import pandas as pd
data = pd.read_csv('DAT SALUD MENTAL - TAMIZAJE.csv', encoding='latin-1', delimiter=",")
data

data.drop('ubigeo', axis = 1, inplace=True)
data.head()

"""Cuando ejecutes este código, verás la cantidad de valores nulos en cada columna del DataFrame. Esto te proporcionará información sobre si hay datos faltantes y en qué columnas específicas. Puedes utilizar esta información como parte de la fase de preparación de datos para decidir cómo manejar los valores nulos, ya sea eliminándolos, imputándolos con algún valor específico o utilizando técnicas más avanzadas dependiendo de tus necesidades."""

print (data.isnull().sum())

"""CATEGORICAL ENCODING

Después de evaluar la relevancia de cada columna, puedes decidir qué columnas mantener y cuáles eliminar. Por ejemplo, podrías eliminar las columnas de ubicación geográfica si no se consideran críticas para tu análisis. Ten en cuenta que estas sugerencias son generales y dependen del conocimiento específico de tu dominio y de los objetivos de tu análisis.
"""

print(data.dtypes)
data.head(1)

# Eliminar las columnas 'Departamento', 'Provincia' y 'Distrito'
data = data.drop(['Departamento', 'Provincia', 'Distrito'], axis=1)

# Mostrar las primeras filas del DataFrame después de eliminar las columnas
print(data.head())

# Convertir columnas categóricas a tipos de datos categóricos
data["Sexo"] = data["Sexo"].astype('category')
data["Etapa"] = data["Etapa"].astype('category')
data["GrupoTamizaje"] = data["GrupoTamizaje"].astype('category')
data["DetalleTamizaje"] = data["DetalleTamizaje"].astype('category')

# Mostrar los tipos de datos después de la conversión
print(data.dtypes)

# Mostrar las primeras filas del DataFrame
print(data.head())

categorical_data=data.drop(['Sexo','Etapa','GrupoTamizaje','DetalleTamizaje'], axis=1)
categorical_data.head()

"""LABEL ENCODING"""

from sklearn.preprocessing import LabelEncoder

# Copiar el conjunto de datos original para no modificar los datos originales
label_data = data.copy()

# Aplicar Label Encoding a las columnas categóricas
label_columns = ['Sexo', 'Etapa', 'GrupoTamizaje', 'DetalleTamizaje']
label_encoder = LabelEncoder()
for column in label_columns:
    label_data[column] = label_encoder.fit_transform(label_data[column])

# Mostrar el conjunto de datos después de aplicar Label Encoding
print(label_data)

"""## ONE-HOT ENCODING"""

# Copiar el conjunto de datos original para no modificar los datos originales
one_hot_data = data.copy()

# Aplicar One-Hot Encoding a las columnas categóricas
one_hot_data = pd.get_dummies(one_hot_data, columns=['Sexo', 'Etapa', 'GrupoTamizaje', 'DetalleTamizaje'], drop_first=True)

# Mostrar el conjunto de datos después de aplicar One-Hot Encoding
print(one_hot_data)

"""## BALANCEAMIENTO DE DATOS OVERSAMPLING"""

print(data.columns)
print(data['Casos'].value_counts())

categorical_data = data.drop(['Etapa','GrupoTamizaje','DetalleTamizaje'], axis=1)
categorical_data["Sexo"] = categorical_data["Sexo"].astype("category")
categorical_data["Sexo"] = categorical_data["Sexo"].cat.codes

result_means = categorical_data.groupby('Casos')['Sexo'].mean()
result_means

# Seleccionar las columnas de interés
selected_columns = ['Casos', 'Sexo']

# Crear un nuevo DataFrame con las columnas seleccionadas
categorical_data = data[selected_columns].copy()  # Utiliza .copy() para evitar la advertencia

# Convertir la columna 'Sexo' a categórica y obtener los códigos
categorical_data["Sexo"] = categorical_data["Sexo"].astype("category")
categorical_data["Sexo"] = categorical_data["Sexo"].cat.codes

# Calcular la media y la suma de 'Sexo' agrupado por 'Casos'
result_means = categorical_data.groupby('Casos')['Sexo'].mean()
result_sums = categorical_data.groupby('Casos')['Sexo'].sum()

# Mostrar los resultados
print("Media de Sexo por Casos:")
print(result_means)

print("\nSuma de Sexo por Casos:")
print(result_sums)

# Crear instancias de RandomUnderSampler solo para la clase mayoritaria si está presente
if 0 in y.value_counts():
    undersampler = RandomUnderSampler(sampling_strategy={0: desired_samples_class_0}, random_state=42)
    X_resampled_under, y_resampled_under = undersampler.fit_resample(X, y)
    # Visualizar la distribución de clases después del undersampling
    plt.figure(figsize=(10, 6))
    ax_resampled_under = pd.Series(y_resampled_under).value_counts().plot(kind='bar', figsize=(10, 6), fontsize=13, color='#057E7C')
    ax_resampled_under.set_title('Distribución de Casos Después del Undersampling', size=20, pad=30)
    ax_resampled_under.set_ylabel('Número de Casos', fontsize=14)
    for i in ax_resampled_under.patches:
        ax_resampled_under.text(i.get_x() + i.get_width() / 2, i.get_height() + 50, str(round(i.get_height(), 2)), fontsize=15, ha='center', va='bottom')
else:
    print("La clase mayoritaria no está presente en los datos.")

# Resto del código para oversampling...

import pandas as pd
from imblearn.over_sampling import RandomOverSampler
from sklearn.model_selection import train_test_split

# Crear un DataFrame con las medias y sumas
data_balance = pd.DataFrame({
    'Casos': result_means.index,
    'Media_Sexo': result_means.values,
    'Suma_Sexo': result_sums.values
})

# Definir las características (X) y la variable objetivo (y)
X = data_balance[['Media_Sexo', 'Suma_Sexo']]
y = data_balance['Casos']

# Dividir el conjunto de datos en entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Utilizar RandomOverSampler para balancear el conjunto de entrenamiento
oversampler = RandomOverSampler(random_state=42)
X_resampled, y_resampled = oversampler.fit_resample(X_train, y_train)

# Mostrar la distribución de clases después del oversampling
print("Distribución de clases después del oversampling:")
print(pd.Series(y_resampled).value_counts())

# Mostrar la distribución de clases después de la selección
class_distribution_selected = data_selected['Casos'].value_counts()
print("Distribución de Clases Después de la Selección:")
print(class_distribution_selected)

oversampler = RandomOverSampler(sampling_strategy={'1': 1000, '2': 1000}, random_state=42)

import pandas as pd
import matplotlib.pyplot as plt
from imblearn.over_sampling import RandomOverSampler
from sklearn.model_selection import train_test_split

# Crear una columna binaria para Casos (1 si es '1', 0 de lo contrario)
data['Casos_binary'] = data['Casos'].apply(lambda x: 1 if x == 1 else 0)

# Mostrar la distribución actual de clases en "Casos_binary"
class_distribution_before = data['Casos_binary'].value_counts()

# Crear un gráfico de barras
plt.figure(figsize=(8, 5))
class_distribution_before.plot(kind='bar', color='blue', alpha=0.7)
plt.title('Distribución Actual de Clases en "Casos_binary"')
plt.xlabel('Clases')
plt.ylabel('Frecuencia')
plt.show()

# Filtrar solo dos clases (0 y 1)
data_selected = data[data['Casos_binary'].isin([0, 1])]

# Dividir el conjunto de datos en entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(data_selected[['Sexo']], data_selected['Casos_binary'], test_size=0.2, random_state=42)

# Utilizar RandomOverSampler para balancear el conjunto de entrenamiento
oversampler = RandomOverSampler(sampling_strategy='auto', random_state=42)
X_resampled, y_resampled = oversampler.fit_resample(X_train, y_train)

# Mostrar la distribución de clases antes y después del oversampling en un gráfico de barras
plt.figure(figsize=(12, 5))

# Distribución de clases antes del oversampling
plt.subplot(1, 2, 1)
class_distribution_before.plot(kind='bar', color='blue', alpha=0.7)
plt.title('Distribución Actual de Clases en "Casos_binary"')
plt.xlabel('Clases')
plt.ylabel('Frecuencia')

# Distribución de clases después del oversampling
plt.subplot(1, 2, 2)
pd.Series(y_resampled).value_counts().plot(kind='bar', color='orange', alpha=0.7)
plt.title('Distribución de Clases Después del Oversampling')
plt.xlabel('Clases')
plt.ylabel('Frecuencia')

plt.tight_layout()
plt.show()

"""## MODELOS"""

import pandas as pd
import matplotlib.pyplot as plt
from imblearn.over_sampling import RandomOverSampler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay
from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay, accuracy_score, roc_curve, roc_auc_score



# Aplicar codificación one-hot a las variables categóricas
categorical_features = ['SEX', 'CA', 'TT', 'TR', 'ET']
X_resampled_encoded = pd.get_dummies(X_resampled, columns=categorical_features, drop_first=True)



# Dividir los datos resampleados en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X_resampled_encoded, y_resampled, test_size=0.2, random_state=2)

"""## MODELO RANDOM FOREST"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelEncoder

# Crear DataFrame con los datos proporcionados
data = {
    'Anio': [2017] * 236527,  # La misma fecha de 2017 para todos los registros
    'NroMes': [1] * 236527,  # El mismo número de mes para todos los registros
    'Casos': [17, 1, 2, 1, 7],  # Ejemplos de casos, reemplaza con tus datos reales
    'Sexo': ['F', 'F', 'F', 'F', 'M'],
    'Etapa': ['18 - 24', '40 - 59', '40 - 59', '80  +', '30 - 39'],
    'GrupoTamizaje': ['TOTAL DE TAMIZAJES', 'SOLO TAMIZAJES POSITIVOS', 'TOTAL DE TAMIZAJES', 'TOTAL DE TAMIZAJES', 'TOTAL DE TAMIZAJES'],
    'DetalleTamizaje': ['SINDROME Y/O TRASTORNO PSICOTICO', 'VIOLENCIA FAMILIAR/MALTRATO INFANTIL', 'TRASTORNO DEPRESIVO', 'SINDROME Y/O TRASTORNO PSICOTICO', 'VIOLENCIA FAMILIAR/MALTRATO INFANTIL']
}

df = pd.DataFrame(data)

# Convertir las variables categóricas a numéricas
le = LabelEncoder()
df['Sexo'] = le.fit_transform(df['Sexo'])
df['Etapa'] = le.fit_transform(df['Etapa'])
df['GrupoTamizaje'] = le.fit_transform(df['GrupoTamizaje'])
df['DetalleTamizaje'] = le.fit_transform(df['DetalleTamizaje'])

# Dividir el conjunto de datos
X = df.drop("Casos", axis=1)
y = df["Casos"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Entrenar Random Forest
rfc = RandomForestClassifier(random_state=42)
rfc.fit(X_train, y_train)

# Predecir en el conjunto de prueba
y_pred = rfc.predict(X_test)

# Calcular la precisión
accuracy = accuracy_score(y_test, y_pred)
print(f"Precisión del modelo: {accuracy * 100:.2f}%")

iimport pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score

# Crear datos de ejemplo
data = {
    'Anio': np.full(236527, 2017),
    'NroMes': np.full(236527, 1),
    'Casos': np.random.randint(1, 20, size=236527),
    'Sexo': np.random.choice(['F', 'M'], size=236527),
    'Etapa': np.random.choice(['18 - 24', '40 - 59', '80  +'], size=236527),
    'GrupoTamizaje': np.random.choice(['TOTAL DE TAMIZAJES', 'SOLO TAMIZAJES POSITIVOS'], size=236527),
    'DetalleTamizaje': np.random.choice(['SINDROME Y/O TRASTORNO PSICOTICO', 'VIOLENCIA FAMILIAR/MALTRATO INFANTIL', 'TRASTORNO DEPRESIVO'], size=236527)
}

# Crear DataFrame
df = pd.DataFrame(data)

# Convertir variables categóricas a numéricas
le = LabelEncoder()
df['Sexo'] = le.fit_transform(df['Sexo'])
df['Etapa'] = le.fit_transform(df['Etapa'])
df['GrupoTamizaje'] = le.fit_transform(df['GrupoTamizaje'])
df['DetalleTamizaje'] = le.fit_transform(df['DetalleTamizaje'])

# Dividir el conjunto de datos en entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(df.drop('Casos', axis=1), df['Casos'], test_size=0.2, random_state=42)

# Entrenar Random Forest
rfc = RandomForestClassifier(random_state=42)
rfc.fit(X_train, y_train)

# Predecir en el conjunto de prueba
y_pred = rfc.predict(X_test)

# Evaluar la precisión
accuracy = accuracy_score(y_test, y_pred)
print(f'Precisión del modelo: {accuracy * 100:.2f}%')

"""## MODELO REGRESION LOGISTICA"""

# Entrenar Logistic Regression y mostrar matriz de confusión
log_reg = LogisticRegression()
log_reg.fit(X_train, y_train)

# Predecir en el conjunto de prueba
y_pred_log_reg = log_reg.predict(X_test)

# Calcular la precisión
accuracy_log_reg = log_reg.score(X_test, y_test)

# Imprimir matriz de confusión
disp_log_reg = ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred_log_reg), display_labels=['No SEXO', 'AC'])
disp_log_reg.plot(cmap='Blues', values_format='d')

# Agregar el porcentaje de precisión en el gráfico
plt.text(0.5, 0.5, f'Accuracy: {round(accuracy_log_reg * 100, 2)}%', color='red', fontsize=12, ha='center', va='center', transform=plt.gca().transAxes)

plt.title('Matriz de Confusión para Logistic Regression')
plt.show()

# Imprimir reporte de clasificación
print("\n--------------------------------------------------------")
print(classification_report(y_test, y_pred_log_reg))
print("\n--------------------------------------------------------")

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Crear datos de ejemplo
data = {
    'Anio': np.full(236527, 2017),
    'NroMes': np.full(236527, 1),
    'Casos': np.random.randint(1, 20, size=236527),
    'Sexo': np.random.choice(['F', 'M'], size=236527),
    'Etapa': np.random.choice(['18 - 24', '40 - 59', '80  +'], size=236527),
    'GrupoTamizaje': np.random.choice(['TOTAL DE TAMIZAJES', 'SOLO TAMIZAJES POSITIVOS'], size=236527),
    'DetalleTamizaje': np.random.choice(['SINDROME Y/O TRASTORNO PSICOTICO', 'VIOLENCIA FAMILIAR/MALTRATO INFANTIL', 'TRASTORNO DEPRESIVO'], size=236527)
}

# Crear DataFrame
df = pd.DataFrame(data)

# Convertir variables categóricas a numéricas
le = LabelEncoder()
df['Sexo'] = le.fit_transform(df['Sexo'])
df['Etapa'] = le.fit_transform(df['Etapa'])
df['GrupoTamizaje'] = le.fit_transform(df['GrupoTamizaje'])
df['DetalleTamizaje'] = le.fit_transform(df['DetalleTamizaje'])

# Dividir el conjunto de datos en entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(df.drop('Casos', axis=1), df['Casos'], test_size=0.2, random_state=42)

# Entrenar Regresión Logística
logreg = LogisticRegression(random_state=42)
logreg.fit(X_train, y_train)

# Predecir en el conjunto de prueba
y_pred = logreg.predict(X_test)

# Imprimir reporte de clasificación
classification_rep = classification_report(y_test, y_pred)
print("Reporte de Clasificación:\n", classification_rep)

# Calcular y mostrar la matriz de confusión
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))
plt.title('Matriz de Confusión')
plt.xlabel('Predicciones')
plt.ylabel('Valores reales')
plt.show()

# Calcular y mostrar la precisión en el gráfico
accuracy = accuracy_score(y_test, y_pred)
plt.figure(figsize=(8, 4))
sns.barplot(x=['Precisión'], y=[accuracy])
plt.title('Porcentaje de Precisión')
plt.ylim(0, 1)
plt.show()

"""Support Vector Machine"""

# Entrenar Support Vector Machine y mostrar matriz de confusión
svc = SVC()
svc.fit(X_train, y_train)

# Predecir en el conjunto de prueba
y_pred_svc = svc.predict(X_test)

# Calcular la precisión
accuracy_svc = svc.score(X_test, y_test)

# Imprimir matriz de confusión
disp_svc = ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred_svc), display_labels=['No AC', 'AC'])
disp_svc.plot(cmap='Blues', values_format='d')

# Agregar el porcentaje de precisión en el gráfico
plt.text(0.5, 0.5, f'Accuracy: {round(accuracy_svc * 100, 2)}%', color='red', fontsize=12, ha='center', va='center', transform=plt.gca().transAxes)

plt.title('Matriz de Confusión para Support Vector Machine')
plt.show()

# Imprimir reporte de clasificación
print("\n--------------------------------------------------------")
print(classification_report(y_test, y_pred_svc))
print("\n--------------------------------------------------------")

"""## Naibe Bayes"""

from sklearn.naive_bayes import GaussianNB

# Entrenar el modelo Naive Bayes
nb = GaussianNB()
nb.fit(X_train, y_train)

# Predecir en el conjunto de prueba
y_pred_nb = nb.predict(X_test)

# Calcular la precisión
accuracy_nb = nb.score(X_test, y_test)

# Imprimir matriz de confusión
disp_nb = ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred_nb), display_labels=['No AC', 'AC'])
disp_nb.plot(cmap='Blues', values_format='d')

# Agregar el porcentaje de precisión en el gráfico
plt.text(0.5, 0.5, f'Accuracy: {round(accuracy_nb * 100, 2)}%', color='red', fontsize=12, ha='center', va='center', transform=plt.gca().transAxes)

plt.title('Matriz de Confusión para Naive Bayes')
plt.show()

# Imprimir reporte de clasificación
print("\n--------------------------------------------------------")
print(classification_report(y_test, y_pred_nb))
print("\n--------------------------------------------------------")